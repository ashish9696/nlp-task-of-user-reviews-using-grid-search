{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "from textstat.textstat import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/analytics_vidya/train.csv\")\n",
    "test = pd.read_csv(\"D:/analytics_vidya/test.csv\")\n",
    "sub = pd.read_csv(\"D:/analytics_vidya/sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31962.000000</td>\n",
       "      <td>31962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15981.500000</td>\n",
       "      <td>0.070146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9226.778988</td>\n",
       "      <td>0.255397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7991.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15981.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23971.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31962.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         label\n",
       "count  31962.000000  31962.000000\n",
       "mean   15981.500000      0.070146\n",
       "std     9226.778988      0.255397\n",
       "min        1.000000      0.000000\n",
       "25%     7991.250000      0.000000\n",
       "50%    15981.500000      0.000000\n",
       "75%    23971.750000      0.000000\n",
       "max    31962.000000      1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xdcfc9b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD3CAYAAAAUl4NyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv9vcjRxlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdcfc208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets=df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def tokenize(tweet):\n",
    "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]*\", tweet.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    \"\"\"Same as tokenize but without the stemming\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", tweet.lower())).strip()\n",
    "    return tweet.split()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words = 'english',\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=10000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we won!!! love the land!!! #allin #cavs #champions #cleveland #clevelandcavaliers  â\\x80¦ '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "for t in range(len(tweets)):\n",
    "    train.append(preprocess(tweets[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 31962)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token = []\n",
    "for text in train:\n",
    "    for t in text:\n",
    "        t = tokenize(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction. #run'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 10000, stop_words = 'english',ngram_range = (1, 3),use_idf=True, smooth_idf=False, norm=None, decode_error='replace',)\n",
    "tfidf = vectorizer.fit_transform(train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get POS tags for tweets and save as a string\n",
    "tweet_tags = []\n",
    "for t in tweets:\n",
    "    tokens = basic_tokenize(preprocess(t))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tag_list = [x[1] for x in tags]\n",
    "    tag_str = \" \".join(tag_list)\n",
    "    tweet_tags.append(tag_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We can use the TFIDF vectorizer to get a token matrix for the POS tags\n",
    "pos_vectorizer = TfidfVectorizer(max_features = 5000, stop_words = 'english',ngram_range = (1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct POS TF matrix and get vocab dict\n",
    "pos = pos_vectorizer.fit_transform(pd.Series(tweet_tags)).toarray()\n",
    "pos_vocab = {v:i for i, v in enumerate(pos_vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now get other features\n",
    "sentiment_analyzer = VS()\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    sentiment = sentiment_analyzer.polarity_scores(tweet)\n",
    "    \n",
    "    words = preprocess(tweet) #Get text only\n",
    "    \n",
    "    syllables = textstat.syllable_count(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    retweet = 0\n",
    "    if \"rt\" in words:\n",
    "        retweet = 1\n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet]\n",
    "    #features = pandas.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\"vader neu\", \\\n",
    "                        \"vader compound\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"is_retweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = get_feature_array(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "M = np.concatenate([tfidf,pos,feats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 15017)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finally get a list of variable names\n",
    "variables = ['']*len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    variables[v] = k\n",
    "\n",
    "pos_variables = ['']*len(pos_vocab)\n",
    "for k,v in pos_vocab.items():\n",
    "    pos_variables[v] = k\n",
    "\n",
    "feature_names = variables+pos_variables+other_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(M)\n",
    "y = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"D:/analytics_vidya/result/X_train.csv\")\n",
    "y_train = pd.read_csv(\"D:/analytics_vidya/result/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "        [('select', SelectFromModel(LogisticRegression(class_weight='balanced',\n",
    "                                                  penalty=\"l1\", C=0.01))),\n",
    "        ('model', LogisticRegression(class_weight='balanced',penalty='l2'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{}] # Optionally add parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe, \n",
    "                           param_grid,\n",
    "                           cv=StratifiedKFold(n_splits=5, \n",
    "                                              random_state=42).split(X_train, y_train), \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv',sep=',')\n",
    "X_test.to_csv('X_test.csv',sep=',')\n",
    "y_train.to_csv('y_train.csv',sep=',')\n",
    "y_test.to_csv('y_test.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n"
     ]
    }
   ],
   "source": [
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = classification_report( y_test, y_preds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,y_preds)\n",
    "matrix_proportions = np.zeros((3,3))\n",
    "for i in range(0,3):\n",
    "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
    "names=['Hate','Offensive','Neither']\n",
    "confusion_df = pd.DataFrame(matrix_proportions, index=names,columns=names)\n",
    "plt.figure(figsize=(5,5))\n",
    "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
    "plt.ylabel(r'True categories',fontsize=14)\n",
    "plt.xlabel(r'Predicted categories',fontsize=14)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "#Uncomment line below if you want to save the output\n",
    "#plt.savefig('confusion.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
